{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_the_data(path):\n",
    "    return pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a quick look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\kk\\Documents\\Python Projects\\California Housing Price\\handson-ml\\datasets\\housing\\housing.csv'\n",
    "df = load_the_data(path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ocean_proximity.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ocean_proximity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(bins=50, figsize = (20,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.median_house_value.between(99000, 110000, inclusive=False)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create a test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### how to share df for train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# we check which indexes we have. we do random permutation for indexes. Then we set how big/ long should be our test set.Here we use our test_ratio.\n",
    "# we split out random permutation array for test and train vector. we take test and train from df\n",
    "def split_train_test(data,test_ratio):\n",
    "    np.random.seed(42)# we need to set random number generator seed's because without generator after some time we will see whole data set in test set, which is what we want to avoid\n",
    "    shuffled_indices = np.random.permutation(len(df))\n",
    "    test_set_size = int(len(df)*test_ratio)\n",
    "    test_indices = shuffled_indices[:test_set_size]\n",
    "    train_indices = shuffled_indices[test_set_size:]\n",
    "    return df.iloc[train_indices],df.iloc[test_indices]\n",
    "train_df, test_df = split_train_test(df,0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### random share with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with sklearn\n",
    "\n",
    "train_set,test_set =train_test_split(df,test_size=0.2,random_state=42)\n",
    "\n",
    "# here we generate train and test set randomly. We need to check if we don't have sampling bias. We always need to do stratified sampling to correct represent f.exp. whole population\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.median_income.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ceil((df.median_income/1.5)).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['median_income_cat'] = np.ceil(df.median_income/1.5)\n",
    "df['median_income_cat'] = df.median_income_cat.where((df.median_income_cat)<5,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### stratified shuffle split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train & test set which we will be use in the project\n",
    "\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1,test_size=0.2,random_state=42)\n",
    "for train_index, test_index in split.split(df,df.median_income_cat):\n",
    "    strat_train_set= df.loc[train_index]\n",
    "    strat_test_set= df.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_test_set.median_income_cat.value_counts()/len(strat_test_set.median_income_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_set,test_set =train_test_split(df,test_size=0.2,random_state=42)\n",
    "test_set.median_income_cat.value_counts()/len(strat_test_set.median_income_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check which test set is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.median_income_cat.value_counts()/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for set_ in (df,strat_test_set,strat_train_set):\n",
    "    set_.drop('median_income_cat',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_train_set.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discover and Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = strat_train_set.copy()\n",
    "housing.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#s- shows popultion and c-shows a median house value\n",
    "housing.plot(kind = 'scatter',x='longitude',y='latitude',alpha=0.1,s=housing['population']/100,label='population',c='median_house_value',cmap=plt.get_cmap('jet'),figsize=(10,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = housing.corr()\n",
    "corr_matrix['median_house_value'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "att = ['median_house_value','median_income','total_rooms','housing_median_age']\n",
    "scatter_matrix(strat_train_set[att])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.plot(kind='scatter',x='median_house_value',y='median_income')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing['rooms_per_household'] = housing['total_rooms']/housing['households']\n",
    "housing['population_per_household'] = housing['population']/housing['households']\n",
    "housing['bedroom_per_room'] = housing['total_bedrooms']/housing['total_rooms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train set and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = strat_train_set.drop('median_house_value',axis=1)\n",
    "housing_label = strat_train_set['median_house_value'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- load the data\n",
    "- discover the data (.info(),.describe(),.shape(),data type, value_counts,correlation between data)\n",
    "- create test and train set -> if it is important that we have good representation we use shuffled\n",
    "- visualize train set,  here important correlation with the label, plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaN and missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.info()\n",
    "# here we see that total bedroom has missing values. We have 3 options:\n",
    "# -get rid of the corresponding district # dropna()\n",
    "# -get rid of the whole attribute # drop()\n",
    "# -set the missing value to some value #fillna()\n",
    "# -Imputer()- works only on numeric data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!!!!!!!!!!!!!!!!!!!!! we need to use this value to replace the NaN value in test set\n",
    "# i will use option 3 with fillna()\n",
    "total_bedrooms_median = housing['total_bedrooms'].median()\n",
    "housing['total_bedrooms'].fillna(total_bedrooms_median,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "imputer = Imputer(strategy='median')\n",
    "\n",
    "housing_num = housing.drop('ocean_proximity',axis=1)\n",
    "imputer.fit(housing_num)\n",
    "X = imputer.transform(housing_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer.statistics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "housing_tr = pd.DataFrame(X,columns= housing_num.columns)\n",
    "housing_tr.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### how Imputer works\n",
    "- we we create Imputer instance ans we need to specify that we want to replace each attribute's missing values with the median\n",
    "- we fit imputer to our numerical attributes\n",
    "- our results are stored in imputer.statistic_\n",
    "- we transform our df and will NaN values with median\n",
    "- after that we can create new df where NaN values are change to median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sckit-Learn Design\n",
    "#### Consistency\n",
    "- Estimator- to estimate values on df. F.exp. Imputer with fit() function. We can set hyperparametr (like stratergy -> 'median')\n",
    "- Transformers- some estimators (f.exp. Imputer) can also transform df. The transform is performed by transform() method with df to transform as a parameter.  Transformation relies on the learned parameters, as in the case for an imputer. We have also fit_transform() method with is equivalent to calling fit() and transform()\n",
    "- Predictors- some estimetors can make predictions for a given df. they are called predictors. F.exp. LinearRegression model was predictor. predict() method take a df of new instances and predict a dataset of corresponding predictions. It has also score() method to measure the quality of the predictions\n",
    "#### Inspection- all hyperparameters are accessible direcltly via public instance variables (imputer.strategy) and all learned parameter are accessible via public instance variables with an underscore suffix (imputer.statistics_) \n",
    "#### Nonproliferation of classes. df are represented as np arrays or scipy sparse martices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling text and categorical attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# factorize()\n",
    "housing_cat = housing['ocean_proximity']\n",
    "housing_cat_encoded, housing_categories = housing_cat.factorize()#encoded categorical value and list of categories \n",
    "\n",
    "# OneHotEncoder()\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "housing_cat_1hot = encoder.fit_transform(housing_cat_encoded.reshape(-1, 1))\n",
    "housing_cat_1hot\n",
    "\n",
    "#CatogoricalEncoder -both transformation cat-> int and int cat -> one-hot in one shot\n",
    "#only avaible in 0.20.dev\n",
    "\n",
    "#from sklearn.preprocessing import CategoricalEncoder\n",
    "#cat_encoder = CategoricalEncoder()\n",
    "#housing_cat_reshape = housing_cat.values.reshape(-1,1)\n",
    "#hosuing_cat_1hot = cat_encoder.fit_transform(housing_cat_reshape)\n",
    "#hosuing_cat_1hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### transform categorical value \n",
    "- factorize()- useful function to transform cat to int. but here our model can think that 0 and 4 is less similar than 0-1- It it mistake and it is a reason why we use binary encoding\n",
    "- OneHotEncoder()- to binary encoding\n",
    "- Categorical\n",
    "- Endocer() can transform cat to int cat and int cat to intin one shot. Only in 0.20.dev\n",
    "- LabelEndocer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Castom Transformers\n",
    "- although sklearn provides many useful transformation we need sometimes write own for tasks such as custom cleanup or combining new attributes\n",
    "##### New transformers need to:\n",
    "- work seamlessly with sckit-learn functions (such as pipelines) \n",
    "All you need is to create a class and implament three methods: fit(), transform(), fit_transform()ßßßßßßßßßßßßßß"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def volume(r):\n",
    "    \"\"\"Returns the volume of a sphere with radius r. \"\"\"\n",
    "    return (4/3)*np.pi*r**3\n",
    "#help(volume)\n",
    "\n",
    "def triangle_area(b,h):\n",
    "    \"\"\"Return triangle are with h-high and b- base\"\"\"\n",
    "    return 0.5*b*h\n",
    "d = triangle_area(3,6)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key word arguments help you to write clean code\n",
    "# 1 inch = 2.54 cm\n",
    "# 1 foot = 12 inches\n",
    "def cm(feet = 0,inches=0):#deflaut values, deflaut arguments\n",
    "    \"\"\"Converts a length from feet and inches to centimeters\"\"\"\n",
    "    inches_to_cm = inches *2.54\n",
    "    feet_to_cm = feet*12*2.54\n",
    "    return inches_to_cm+feet_to_cm\n",
    "\n",
    "cm(feet=5)\n",
    "cm(inches=70)\n",
    "cm(5,8)\n",
    "    \n",
    "# if we have keyword arguments (f.exp feet =5) and required arguments (r- without - sign) we need to specify required arguments firts\n",
    "#required arguments are specify with its position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rooms_ix,bedrooms_ix,population_ix, household_ix = 3,4,5,6\n",
    "\n",
    "class CombinedAttributesAdder(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self, add_bedrooms_per_room=True):\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "    def fit(self,X, y=None):\n",
    "        return self\n",
    "    def transform(self,X, y=None):\n",
    "        rooms_per_household = X[:,rooms_ix]/X[:,household_ix]\n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room = X[:,bedrooms_ix]/X[:,rooms_ix]\n",
    "            return np.c_[X,rooms_per_household,bedrooms_per_room]\n",
    "        else:\n",
    "            return np.c_[X,rooms_per_household]\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = CombinedAttributesAdder()\n",
    "r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Circle:\n",
    "    def __init__(self,radius):\n",
    "        self.radius = radius\n",
    "    def circle_area(self):\n",
    "        return np.pi*self.radius**2\n",
    "    def perimeter(self):\n",
    "        return np.pi*self.radius*2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circle1 = Circle(4)\n",
    "circle1.circle_area()\n",
    "circle1.perimeter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l =[Circle(i) for i in range(20)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- NaN\n",
    "- ocean_proximity obj -> one_hot\n",
    "- dodatkowe artybuty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RemoveNaN(TransformerMixin):\n",
    "    def __init__(self,filling_strategy = 'median'):\n",
    "        self.filling_strategy = filling_strategy\n",
    "    def fit(self,X):\n",
    "        return self\n",
    "    def transform(self,X):\n",
    "        if self.filling_strategy == 'median':\n",
    "            for col in X.select_dtypes('float64'):\n",
    "                col_median = X[col].median()\n",
    "                X[col].fillna(col_median)\n",
    "            return X\n",
    "                \n",
    "        else:\n",
    "            for col in X.select_dtypes('float64'):\n",
    "                col_mean = X[col].mean()\n",
    "                X[col].fillna(col_mean)\n",
    "            return X\n",
    "            \n",
    "\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = RemoveNaN()\n",
    "d1 = d1.fit_transform(housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ChangeObjectToInt:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self,X):\n",
    "        return self\n",
    "    def transform(self,X):\n",
    "        for col in X.select_dtypes('object'):\n",
    "            cat_to_int = pd.get_dummies(X[col],prefix = col)\n",
    "            X = X.join(cat_to_int)\n",
    "            X = X.drop(col,axis=1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = ChangeObjectToInt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.transform(housing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feauture scaling\n",
    "- normalization- we scale the data between 0-1. We substract min value and divide max-min\n",
    "- standarization- we substract mean and divide std. Standarization is less affected by outliners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation Pipelines\n",
    "- pipeline helps by execute sequence of transformation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline([('imputer',Imputer(strategy='median')),\n",
    "                         ('attribs_adder',CombinedAttributesAdder)\n",
    "                         ('std_scaler',StandardScaler())])\n",
    "\n",
    "housing_num_tr = num_pipeline.fit_transform(housing_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrameSelector(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self,attributes_name):\n",
    "        self.attributes_name = attributes_name\n",
    "        \n",
    "    def fit(self,X):\n",
    "        return self\n",
    "    def transform(self,X):\n",
    "        \n",
    "        return X[self.attributes_name].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_attr = list(housing_num)\n",
    "cat_attr = ['ocean_proximity']\n",
    "num_pipeline = Pipeline([('selector',DataFrameSelector(num_attr)),\n",
    "                         ('imputer',Imputer(strategy='median')),\n",
    "                         ('attribs_adder',CombinedAttributesAdder()),\n",
    "                         ('std_scaler',StandardScaler())])\n",
    "\n",
    "cat_pipeline = Pipeline([('selector',DataFrameSelector(cat_attr)),\n",
    "                         ('onehot',OneHotEncoder())])\n",
    "\n",
    "## to connect two pipelines in one\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "full_pipeline = FeatureUnion(transformer_list=[('num_pipeline',num_pipeline),('cat_pipeline',cat_pipeline)])\n",
    "housing_prepared = full_pipeline.fit_transform(housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline.fit_transform(housing).shape\n",
    "full_pipeline.transform(housing).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression()\n",
    "decision_tree = DecisionTreeRegressor()\n",
    "random_forest = RandomForestRegressor()\n",
    "svm = SVR()\n",
    "\n",
    "model_list = [lin_reg, decision_tree, random_forest,svm]\n",
    "rmse_results = []\n",
    "param_grid =[{'normalize':[True,False]},\n",
    "             {'min_samples_split':[4,12],'max_features':[2,4,6,10]},\n",
    "             {'n_estimators':[3,10,30],'max_features':[2,4,6,8]},\n",
    "             {'C': [1, 10, 100, 1000], 'kernel': ['linear','rbf']}]\n",
    "\n",
    "param = [{'normalize':[True,False]},\n",
    "         {'min_samples_split':randint(4,12),'max_features':randint(2,15)},\n",
    "         {'n_estimators':randint(10,30),'max_features':randint(2,15)},\n",
    "         {'C': randint(500,2000), 'kernel': ['linear','rbf'],'gamma':[0.0001,0.0005,0.001]}]\n",
    "\n",
    "for c,model in enumerate(model_list):\n",
    "    #rmse on training set\n",
    "    model.fit(housing_prepared,housing_label)\n",
    "    housing_prediction = model.predict(housing_prepared)\n",
    "    rmse_training = np.sqrt(mean_squared_error(housing_label,housing_prediction))\n",
    "    #rmse on validation set\n",
    "    scores = cross_val_score(model,housing_prepared,housing_label,scoring='neg_mean_squared_error',cv=10)\n",
    "    rmse_validation = np.sqrt(-scores)\n",
    "    #grid serach\n",
    "    grid_search = GridSearchCV(model,param_grid[c],cv=5,scoring='neg_mean_squared_error')\n",
    "    grid_search.fit(housing_prepared,housing_label)\n",
    "    grid_results = grid_search.cv_results_\n",
    "    rmse_grid = min(np.sqrt(-grid_results['mean_test_score']))\n",
    "    #randomized search\n",
    "    random_search = RandomizedSearchCV(model,param[c],cv=30,scoring='neg_mean_squared_error')\n",
    "    random_search.fit(housing_prepared,housing_label)\n",
    "    random_results = random_search.cv_results_\n",
    "    rmse_random = min(np.sqrt(-random_results['mean_test_score']))\n",
    "    rmse_results.append({'model_name':str(model_list[c]).split('(')[0],'val_rmse:':np.mean(rmse_validation),'train_rmse':rmse_training,'rmse_grid':rmse_grid, 'rmse_randomized':rmse_random})\n",
    "pd.DataFrame(rmse_results)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = pd.DataFrame(rmse_results)\n",
    "rmse.to_csv('rmse.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params =  [\n",
    "  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "  {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
    " ]\n",
    "grid_svm = GridSearchCV(svm,params,cv=5,scoring='neg_mean_squared_error')\n",
    "grid_svm.fit(housing_prepared,housing_label)\n",
    "grid_results = grid_svm.cv_results_\n",
    "rmse_svr = min(np.sqrt(-grid_results['mean_test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mean, param in zip(np.sqrt(-grid_results['mean_test_score']),grid_results['params']):\n",
    "    print(mean,param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(rmse_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV for transformer -> CombinedAttributesAdder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipeline with a scaler \n",
    "combined = CombinedAttributesAdder()\n",
    "steps = [('combined_attributes',combined),('random_forest',random_forest)]\n",
    "pipeline = Pipeline(steps)\n",
    "#parameters\n",
    "param =  {'combined_attributes__add_bedrooms_per_room': [True,False]}\n",
    "#do search\n",
    "grid_search_extra_param = GridSearchCV(pipeline,param,cv=5,scoring='neg_mean_squared_error')\n",
    "grid_search_extra_param.fit(housing_prepared.toarray(), housing_label)\n",
    "grid_results = grid_search_extra_param.cv_results_\n",
    "grid_results['mean_test_score']\n",
    "rmse_grid_extra_param = min(np.sqrt(-grid_results['mean_test_score']))\n",
    "rmse_grid_extra_param\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
